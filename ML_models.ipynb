{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPecIE03bYLYGsmHUwjuvGT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahulamatapu/Community-Perspectives/blob/master/ML_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XG Boost"
      ],
      "metadata": {
        "id": "lHzG7PEHizmp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XP8LBcTEiYhv",
        "outputId": "9cf30cf7-4304-4fe2-9211-51ce91494f8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\teval-logloss:0.62777\n",
            "[1]\teval-logloss:0.60607\n",
            "[2]\teval-logloss:0.59064\n",
            "[3]\teval-logloss:0.57637\n",
            "[4]\teval-logloss:0.56190\n",
            "[5]\teval-logloss:0.55219\n",
            "[6]\teval-logloss:0.54112\n",
            "[7]\teval-logloss:0.53236\n",
            "[8]\teval-logloss:0.52409\n",
            "[9]\teval-logloss:0.52107\n",
            "[10]\teval-logloss:0.51364\n",
            "[11]\teval-logloss:0.51038\n",
            "[12]\teval-logloss:0.50555\n",
            "[13]\teval-logloss:0.50064\n",
            "[14]\teval-logloss:0.49641\n",
            "[15]\teval-logloss:0.49419\n",
            "[16]\teval-logloss:0.49069\n",
            "[17]\teval-logloss:0.48804\n",
            "[18]\teval-logloss:0.48642\n",
            "[19]\teval-logloss:0.48520\n",
            "[20]\teval-logloss:0.48347\n",
            "[21]\teval-logloss:0.48130\n",
            "[22]\teval-logloss:0.48113\n",
            "[23]\teval-logloss:0.48017\n",
            "[24]\teval-logloss:0.47952\n",
            "[25]\teval-logloss:0.47869\n",
            "[26]\teval-logloss:0.47807\n",
            "[27]\teval-logloss:0.47824\n",
            "[28]\teval-logloss:0.47804\n",
            "[29]\teval-logloss:0.47756\n",
            "[30]\teval-logloss:0.47682\n",
            "[31]\teval-logloss:0.47662\n",
            "[32]\teval-logloss:0.47651\n",
            "[33]\teval-logloss:0.47630\n",
            "[34]\teval-logloss:0.47541\n",
            "[35]\teval-logloss:0.47533\n",
            "[36]\teval-logloss:0.47562\n",
            "[37]\teval-logloss:0.47567\n",
            "[38]\teval-logloss:0.47543\n",
            "[39]\teval-logloss:0.47438\n",
            "[40]\teval-logloss:0.47480\n",
            "[41]\teval-logloss:0.47480\n",
            "[42]\teval-logloss:0.47495\n",
            "[43]\teval-logloss:0.47465\n",
            "[44]\teval-logloss:0.47513\n",
            "[45]\teval-logloss:0.47507\n",
            "[46]\teval-logloss:0.47532\n",
            "[47]\teval-logloss:0.47525\n",
            "[48]\teval-logloss:0.47544\n",
            "Accuracy: 0.755\n",
            "AUC: 0.8292994505494506\n",
            "\n",
            "Feature importance:\n",
            "action_2: 6.447959899902344\n",
            "facility_2: 4.775937557220459\n",
            "action_1: 4.587119102478027\n",
            "facility_1: 2.9105212688446045\n",
            "community_1: 1.654259443283081\n",
            "community_2: 1.4757397174835205\n",
            "social_vulnerability_score: 0.7854515314102173\n",
            "community: 0.5940820574760437\n",
            "population: 0.5020315647125244\n",
            "\n",
            "Overall Rankings:\n",
            "1. Repair Water Commercial in Community 2 (Score: 1475.08)\n",
            "2. Repair Water Residential in Community 3 (Score: 1203.24)\n",
            "3. Repair Water Residential in Community 2 (Score: 960.95)\n",
            "4. Repair Power Residential in Community 3 (Score: 946.10)\n",
            "5. Repair Water Residential in Community 1 (Score: 774.98)\n",
            "6. Repair Power Residential in Community 2 (Score: 718.35)\n",
            "7. Repair Power Residential in Community 1 (Score: 688.14)\n",
            "8. Repair Water School in Community 3 (Score: 458.14)\n",
            "9. Repair Water School in Community 1 (Score: 295.23)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import ndcg_score\n",
        "import csv\n",
        "from io import StringIO\n",
        "import ast\n",
        "\n",
        "# Read the file content\n",
        "with open('community_focused_unbiased_data.csv', 'r') as file:\n",
        "    content = file.read()\n",
        "\n",
        "# Use the csv module to handle proper parsing of nested commas in ordered_pair column\n",
        "data = list(csv.reader(StringIO(content)))\n",
        "\n",
        "# Extract header and data\n",
        "header = data[0]\n",
        "data = data[1:]\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame(data, columns=header)\n",
        "\n",
        "# Strip whitespace from column names\n",
        "df.columns = df.columns.str.strip()\n",
        "\n",
        "# Convert numeric columns\n",
        "df['population'] = pd.to_numeric(df['population'])\n",
        "df['social_vulnerability_score'] = pd.to_numeric(df['social_vulnerability_score'])\n",
        "df['access_to_resources'] = pd.to_numeric(df['access_to_resources'])\n",
        "\n",
        "# Parse the ordered_pair string into a list\n",
        "df['ordered_pair'] = df['ordered_pair'].apply(ast.literal_eval)\n",
        "\n",
        "# Create label based on ordered_pair\n",
        "df['label'] = (df['ordered_pair'].apply(lambda x: x[0]) == df['option1']).astype(int)\n",
        "\n",
        "# Function to encode repair options\n",
        "def encode_repair_option(option):\n",
        "    action = 1 if 'Water' in option else 0\n",
        "    facility = 2 if 'School' in option else (1 if 'Residential' in option else 0)\n",
        "    community = int(option.split()[-1]) - 1\n",
        "    return action, facility, community\n",
        "\n",
        "# Encode options\n",
        "df[['action_1', 'facility_1', 'community_1']] = df['option1'].apply(encode_repair_option).tolist()\n",
        "df[['action_2', 'facility_2', 'community_2']] = df['option2'].apply(encode_repair_option).tolist()\n",
        "\n",
        "# Prepare features\n",
        "categorical_features = ['community', 'action_1', 'facility_1', 'community_1', 'action_2', 'facility_2', 'community_2']\n",
        "numerical_features = ['population', 'social_vulnerability_score', 'access_to_resources']\n",
        "\n",
        "# Encode categorical features\n",
        "le = LabelEncoder()\n",
        "for feature in categorical_features:\n",
        "    df[feature] = le.fit_transform(df[feature])\n",
        "\n",
        "# Normalize numerical features\n",
        "scaler = StandardScaler()\n",
        "df[numerical_features] = scaler.fit_transform(df[numerical_features])\n",
        "\n",
        "# Prepare features and target\n",
        "features = categorical_features + numerical_features\n",
        "X = df[features]\n",
        "y = df['label']\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create DMatrix for XGBoost\n",
        "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
        "dtest = xgb.DMatrix(X_test, label=y_test)\n",
        "\n",
        "# Set parameters\n",
        "params = {\n",
        "    'objective': 'binary:logistic',\n",
        "    'eta': 0.1,\n",
        "    'max_depth': 6,\n",
        "    'min_child_weight': 1,\n",
        "    'subsample': 0.8,\n",
        "    'colsample_bytree': 0.8,\n",
        "    'tree_method': 'hist'\n",
        "}\n",
        "\n",
        "# Train the model\n",
        "model = xgb.train(\n",
        "    params,\n",
        "    dtrain,\n",
        "    num_boost_round=100,\n",
        "    evals=[(dtest, 'eval')],\n",
        "    early_stopping_rounds=10,\n",
        "    verbose_eval=True\n",
        ")\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(dtest)\n",
        "\n",
        "# Evaluate the model\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "accuracy = accuracy_score(y_test, y_pred > 0.5)\n",
        "auc = roc_auc_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"AUC: {auc}\")\n",
        "\n",
        "# Feature importance\n",
        "print(\"\\nFeature importance:\")\n",
        "importance = model.get_score(importance_type='gain')\n",
        "for feature, score in sorted(importance.items(), key=lambda x: x[1], reverse=True):\n",
        "    print(f\"{feature}: {score}\")\n",
        "\n",
        "# Function to get ranking for all repair options\n",
        "def get_overall_ranking(model, df, features):\n",
        "    all_options = set(df['option1'].unique()) | set(df['option2'].unique())\n",
        "    option_scores = {option: 0 for option in all_options}\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        context = row[['community', 'population', 'social_vulnerability_score', 'access_to_resources']].values\n",
        "        for option in all_options:\n",
        "            action, facility, community = encode_repair_option(option)\n",
        "            feature_values = np.concatenate([context, [action, facility, community, 0, 0, 0]])\n",
        "            feature_dict = dict(zip(features, feature_values))\n",
        "            score = model.predict(xgb.DMatrix(pd.DataFrame([feature_dict])))[0]\n",
        "            option_scores[option] += score\n",
        "\n",
        "    return sorted(option_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# Get overall ranking\n",
        "overall_ranking = get_overall_ranking(model, df, features)\n",
        "\n",
        "print(\"\\nOverall Rankings:\")\n",
        "for rank, (option, score) in enumerate(overall_ranking, 1):\n",
        "    print(f\"{rank}. {option} (Score: {score:.2f})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XG Boost with Tuning"
      ],
      "metadata": {
        "id": "eE2g-soBi6BS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "import csv\n",
        "from io import StringIO\n",
        "import ast\n",
        "\n",
        "# Read and preprocess data\n",
        "with open('community_focused_unbiased_data.csv', 'r') as file:\n",
        "    content = file.read()\n",
        "\n",
        "data = list(csv.reader(StringIO(content)))\n",
        "header, data = data[0], data[1:]\n",
        "df = pd.DataFrame(data, columns=header)\n",
        "df.columns = df.columns.str.strip()\n",
        "\n",
        "df['population'] = pd.to_numeric(df['population'])\n",
        "df['social_vulnerability_score'] = pd.to_numeric(df['social_vulnerability_score'])\n",
        "df['access_to_resources'] = pd.to_numeric(df['access_to_resources'])\n",
        "\n",
        "df['ordered_pair'] = df['ordered_pair'].apply(ast.literal_eval)\n",
        "df['label'] = (df['ordered_pair'].apply(lambda x: x[0]) == df['option1']).astype(int)\n",
        "\n",
        "def encode_repair_option(option):\n",
        "    action = 1 if 'Water' in option else 0\n",
        "    facility = 2 if 'School' in option else (1 if 'Residential' in option else 0)\n",
        "    community = int(option.split()[-1]) - 1\n",
        "    return action, facility, community\n",
        "\n",
        "df[['action_1', 'facility_1', 'community_1']] = df['option1'].apply(encode_repair_option).tolist()\n",
        "df[['action_2', 'facility_2', 'community_2']] = df['option2'].apply(encode_repair_option).tolist()\n",
        "\n",
        "categorical_features = ['community', 'action_1', 'facility_1', 'community_1', 'action_2', 'facility_2', 'community_2']\n",
        "numerical_features = ['population', 'social_vulnerability_score', 'access_to_resources']\n",
        "\n",
        "le = LabelEncoder()\n",
        "for feature in categorical_features:\n",
        "    df[feature] = le.fit_transform(df[feature])\n",
        "\n",
        "scaler = StandardScaler()\n",
        "df[numerical_features] = scaler.fit_transform(df[numerical_features])\n",
        "\n",
        "features = categorical_features + numerical_features\n",
        "X = df[features]\n",
        "y = df['label']\n",
        "\n",
        "# Feature engineering\n",
        "X['pop_vulnerability'] = X['population'] * X['social_vulnerability_score']\n",
        "X['action1_vulnerability'] = X['action_1'] * X['social_vulnerability_score']\n",
        "X['action2_vulnerability'] = X['action_2'] * X['social_vulnerability_score']\n",
        "features = list(X.columns)\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Hyperparameter tuning\n",
        "param_grid = {\n",
        "    'max_depth': [3, 4, 5, 6],\n",
        "    'min_child_weight': [1, 2, 3],\n",
        "    'subsample': [0.7, 0.8, 0.9],\n",
        "    'colsample_bytree': [0.7, 0.8, 0.9]\n",
        "}\n",
        "\n",
        "xgb_model = xgb.XGBClassifier(objective='binary:logistic', n_estimators=100, learning_rate=0.1)\n",
        "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=3, scoring='roc_auc', n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best parameters:\", grid_search.best_params_)\n",
        "print(\"Best AUC:\", grid_search.best_score_)\n",
        "\n",
        "# Evaluate on test set\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "test_accuracy = accuracy_score(y_test, y_pred)\n",
        "test_auc = roc_auc_score(y_test, best_model.predict_proba(X_test)[:, 1])\n",
        "\n",
        "print(f\"Test Accuracy: {test_accuracy}\")\n",
        "print(f\"Test AUC: {test_auc}\")\n",
        "\n",
        "# Analyze misclassifications\n",
        "misclassified = X_test[y_test != y_pred]\n",
        "print(\"\\nMisclassified samples:\")\n",
        "print(misclassified.describe())\n",
        "\n",
        "# Get feature importance\n",
        "importance = best_model.feature_importances_\n",
        "feature_importance = sorted(zip(features, importance), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "print(\"\\nFeature Importance:\")\n",
        "for feature, importance in feature_importance:\n",
        "    print(f\"{feature}: {importance:.4f}\")\n",
        "\n",
        "# Function to get ranking for all repair options\n",
        "def get_overall_ranking(model, df, features):\n",
        "    all_options = set(df['option1'].unique()) | set(df['option2'].unique())\n",
        "    option_scores = {option: 0 for option in all_options}\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        context = row[['community', 'population', 'social_vulnerability_score', 'access_to_resources']].values\n",
        "        for option in all_options:\n",
        "            action, facility, community = encode_repair_option(option)\n",
        "            base_features = np.concatenate([context, [action, facility, community, 0, 0, 0]])\n",
        "\n",
        "            # Calculate additional features\n",
        "            pop_vulnerability = base_features[1] * base_features[2]  # population * social_vulnerability_score\n",
        "            action1_vulnerability = action * base_features[2]  # action * social_vulnerability_score\n",
        "            action2_vulnerability = 0 * base_features[2]  # We use 0 for action_2 as it's not the current option\n",
        "\n",
        "            feature_values = np.concatenate([base_features, [pop_vulnerability, action1_vulnerability, action2_vulnerability]])\n",
        "            feature_dict = dict(zip(features, feature_values))\n",
        "            score = model.predict_proba(pd.DataFrame([feature_dict]))[0, 1]\n",
        "            option_scores[option] += score\n",
        "\n",
        "    return sorted(option_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# Get overall ranking with the best model\n",
        "overall_ranking = get_overall_ranking(best_model, df, X.columns)\n",
        "\n",
        "print(\"\\nOverall Rankings (Best Model):\")\n",
        "for rank, (option, score) in enumerate(overall_ranking, 1):\n",
        "    print(f\"{rank}. {option} (Score: {score:.2f})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEciu4WxjPkh",
        "outputId": "1b29fcfb-4220-4774-97bd-8f7013056c93"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-f5619d756e61>:51: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X['pop_vulnerability'] = X['population'] * X['social_vulnerability_score']\n",
            "<ipython-input-2-f5619d756e61>:52: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X['action1_vulnerability'] = X['action_1'] * X['social_vulnerability_score']\n",
            "<ipython-input-2-f5619d756e61>:53: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X['action2_vulnerability'] = X['action_2'] * X['social_vulnerability_score']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters: {'colsample_bytree': 0.9, 'max_depth': 6, 'min_child_weight': 3, 'subsample': 0.9}\n",
            "Best AUC: 0.8243760002517487\n",
            "Test Accuracy: 0.7525\n",
            "Test AUC: 0.8284752747252747\n",
            "\n",
            "Misclassified samples:\n",
            "       community   action_1  facility_1  community_1   action_2  facility_2  \\\n",
            "count  99.000000  99.000000   99.000000    99.000000  99.000000   99.000000   \n",
            "mean    0.808081   0.525253    1.131313     0.434343   0.808081    1.151515   \n",
            "std     0.804030   0.501903    0.527730     0.608806   0.395814    0.541420   \n",
            "min     0.000000   0.000000    0.000000     0.000000   0.000000    0.000000   \n",
            "25%     0.000000   0.000000    1.000000     0.000000   1.000000    1.000000   \n",
            "50%     1.000000   1.000000    1.000000     0.000000   1.000000    1.000000   \n",
            "75%     1.000000   1.000000    1.000000     1.000000   1.000000    1.000000   \n",
            "max     2.000000   1.000000    2.000000     2.000000   1.000000    2.000000   \n",
            "\n",
            "       community_2  population  social_vulnerability_score  \\\n",
            "count    99.000000   99.000000                   99.000000   \n",
            "mean      1.575758   -0.228126                    0.230451   \n",
            "std       0.607620    0.979780                    1.004301   \n",
            "min       0.000000   -1.192096                   -1.142073   \n",
            "25%       1.000000   -1.192096                   -0.168024   \n",
            "50%       2.000000   -0.048207                   -0.168024   \n",
            "75%       2.000000   -0.048207                    1.293051   \n",
            "max       2.000000    1.259095                    1.293051   \n",
            "\n",
            "       access_to_resources  pop_vulnerability  action1_vulnerability  \\\n",
            "count            99.000000          99.000000              99.000000   \n",
            "mean             -0.229219          -1.015497               0.192153   \n",
            "std               0.985984           0.712185               0.717075   \n",
            "min              -1.220170          -1.541440              -1.142073   \n",
            "25%              -1.220170          -1.541440              -0.168024   \n",
            "50%               0.006132          -1.437978               0.000000   \n",
            "75%               0.006132           0.008100               0.646525   \n",
            "max               1.232433           0.008100               1.293051   \n",
            "\n",
            "       action2_vulnerability  \n",
            "count              99.000000  \n",
            "mean                0.129873  \n",
            "std                 0.903433  \n",
            "min                -1.142073  \n",
            "25%                -0.168024  \n",
            "50%                 0.000000  \n",
            "75%                 1.293051  \n",
            "max                 1.293051  \n",
            "\n",
            "Feature Importance:\n",
            "action_2: 0.2192\n",
            "facility_2: 0.1617\n",
            "action_1: 0.1428\n",
            "action1_vulnerability: 0.1083\n",
            "facility_1: 0.0900\n",
            "community_1: 0.0678\n",
            "community_2: 0.0545\n",
            "action2_vulnerability: 0.0529\n",
            "pop_vulnerability: 0.0402\n",
            "population: 0.0241\n",
            "community: 0.0203\n",
            "social_vulnerability_score: 0.0182\n",
            "access_to_resources: 0.0000\n",
            "\n",
            "Overall Rankings (Best Model):\n",
            "1. Repair Water Commercial in Community 2 (Score: 1605.23)\n",
            "2. Repair Water Residential in Community 3 (Score: 1126.63)\n",
            "3. Repair Water Residential in Community 2 (Score: 826.25)\n",
            "4. Repair Power Residential in Community 3 (Score: 815.79)\n",
            "5. Repair Water Residential in Community 1 (Score: 644.68)\n",
            "6. Repair Power Residential in Community 2 (Score: 607.81)\n",
            "7. Repair Power Residential in Community 1 (Score: 547.90)\n",
            "8. Repair Water School in Community 3 (Score: 438.99)\n",
            "9. Repair Water School in Community 1 (Score: 237.52)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "eJxkA5Lfnhss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install trueskill"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlHhScQOjf7f",
        "outputId": "63448fae-8a9a-406c-fe61-8d53a9e8795e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting trueskill\n",
            "  Downloading trueskill-0.4.5.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from trueskill) (1.16.0)\n",
            "Building wheels for collected packages: trueskill\n",
            "  Building wheel for trueskill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for trueskill: filename=trueskill-0.4.5-py3-none-any.whl size=18048 sha256=3a34ecc320e2072fd9e914d8e2237b97e8f9a64d13d7951a3649d1494bb03a63\n",
            "  Stored in directory: /root/.cache/pip/wheels/b9/4f/29/c79f0a2956775524c7a23638ac2b6fbb516c680f8e5eed9b53\n",
            "Successfully built trueskill\n",
            "Installing collected packages: trueskill\n",
            "Successfully installed trueskill-0.4.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PageRank and TrueSkill\n"
      ],
      "metadata": {
        "id": "Gz_gcgBNojdI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "import csv\n",
        "from io import StringIO\n",
        "import ast\n",
        "import networkx as nx\n",
        "from trueskill import Rating, quality_1vs1, rate_1vs1\n",
        "from scipy.stats import kendalltau\n",
        "\n",
        "# Read and preprocess data\n",
        "with open('community_focused_unbiased_data.csv', 'r') as file:\n",
        "    content = file.read()\n",
        "\n",
        "data = list(csv.reader(StringIO(content)))\n",
        "header, data = data[0], data[1:]\n",
        "df = pd.DataFrame(data, columns=header)\n",
        "df.columns = df.columns.str.strip()\n",
        "\n",
        "df['population'] = pd.to_numeric(df['population'])\n",
        "df['social_vulnerability_score'] = pd.to_numeric(df['social_vulnerability_score'])\n",
        "df['access_to_resources'] = pd.to_numeric(df['access_to_resources'])\n",
        "\n",
        "df['ordered_pair'] = df['ordered_pair'].apply(ast.literal_eval)\n",
        "df['label'] = (df['ordered_pair'].apply(lambda x: x[0]) == df['option1']).astype(int)\n",
        "\n",
        "def encode_repair_option(option):\n",
        "    action = 1 if 'Water' in option else 0\n",
        "    facility = 2 if 'School' in option else (1 if 'Residential' in option else 0)\n",
        "    community = int(option.split()[-1]) - 1\n",
        "    return action, facility, community\n",
        "\n",
        "df[['action_1', 'facility_1', 'community_1']] = df['option1'].apply(encode_repair_option).tolist()\n",
        "df[['action_2', 'facility_2', 'community_2']] = df['option2'].apply(encode_repair_option).tolist()\n",
        "\n",
        "categorical_features = ['community', 'action_1', 'facility_1', 'community_1', 'action_2', 'facility_2', 'community_2']\n",
        "numerical_features = ['population', 'social_vulnerability_score', 'access_to_resources']\n",
        "\n",
        "le = LabelEncoder()\n",
        "for feature in categorical_features:\n",
        "    df[feature] = le.fit_transform(df[feature])\n",
        "\n",
        "scaler = StandardScaler()\n",
        "df[numerical_features] = scaler.fit_transform(df[numerical_features])\n",
        "\n",
        "features = categorical_features + numerical_features\n",
        "X = df[features]\n",
        "y = df['label']\n",
        "\n",
        "# Feature engineering\n",
        "X['pop_vulnerability'] = X['population'] * X['social_vulnerability_score']\n",
        "X['action1_vulnerability'] = X['action_1'] * X['social_vulnerability_score']\n",
        "X['action2_vulnerability'] = X['action_2'] * X['social_vulnerability_score']\n",
        "features = list(X.columns)\n",
        "\n",
        "# Train XGBoost model\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "xgb_model = xgb.XGBClassifier(objective='binary:logistic', n_estimators=100, learning_rate=0.1)\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "# PageRank ranking\n",
        "def pagerank_ranking(df):\n",
        "    G = nx.DiGraph()\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        option1 = row['option1']\n",
        "        option2 = row['option2']\n",
        "        preference = row['label']\n",
        "\n",
        "        if preference == 1:\n",
        "            G.add_edge(option1, option2)\n",
        "        else:\n",
        "            G.add_edge(option2, option1)\n",
        "\n",
        "    pagerank = nx.pagerank(G)\n",
        "    return sorted(pagerank.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# TrueSkill ranking\n",
        "def trueskill_ranking(df):\n",
        "    ratings = {}\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        option1 = row['option1']\n",
        "        option2 = row['option2']\n",
        "        preference = row['label']\n",
        "\n",
        "        if option1 not in ratings:\n",
        "            ratings[option1] = Rating()\n",
        "        if option2 not in ratings:\n",
        "            ratings[option2] = Rating()\n",
        "\n",
        "        if preference == 1:\n",
        "            ratings[option1], ratings[option2] = rate_1vs1(ratings[option1], ratings[option2])\n",
        "        else:\n",
        "            ratings[option2], ratings[option1] = rate_1vs1(ratings[option2], ratings[option1])\n",
        "\n",
        "    return sorted(ratings.items(), key=lambda x: x[1].mu, reverse=True)\n",
        "\n",
        "# XGBoost ranking\n",
        "def get_xgboost_ranking(model, df, features):\n",
        "    all_options = set(df['option1'].unique()) | set(df['option2'].unique())\n",
        "    option_scores = {option: 0 for option in all_options}\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        context = row[['community', 'population', 'social_vulnerability_score', 'access_to_resources']].values\n",
        "        for option in all_options:\n",
        "            action, facility, community = encode_repair_option(option)\n",
        "            base_features = np.concatenate([context, [action, facility, community, 0, 0, 0]])\n",
        "\n",
        "            pop_vulnerability = base_features[1] * base_features[2]\n",
        "            action1_vulnerability = action * base_features[2]\n",
        "            action2_vulnerability = 0 * base_features[2]\n",
        "\n",
        "            feature_values = np.concatenate([base_features, [pop_vulnerability, action1_vulnerability, action2_vulnerability]])\n",
        "            feature_dict = dict(zip(features, feature_values))\n",
        "            score = model.predict_proba(pd.DataFrame([feature_dict]))[0, 1]\n",
        "            option_scores[option] += score\n",
        "\n",
        "    return sorted(option_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# Calculate rankings\n",
        "pagerank_results = pagerank_ranking(df)\n",
        "trueskill_results = trueskill_ranking(df)\n",
        "xgboost_results = get_xgboost_ranking(xgb_model, df, features)\n",
        "\n",
        "# Print rankings\n",
        "print(\"PageRank Rankings:\")\n",
        "for rank, (option, score) in enumerate(pagerank_results, 1):\n",
        "    print(f\"{rank}. {option} (Score: {score:.4f})\")\n",
        "\n",
        "print(\"\\nTrueSkill Rankings:\")\n",
        "for rank, (option, rating) in enumerate(trueskill_results, 1):\n",
        "    print(f\"{rank}. {option} (Score: {rating.mu:.2f} ± {rating.sigma:.2f})\")\n",
        "\n",
        "print(\"\\nXGBoost Rankings:\")\n",
        "for rank, (option, score) in enumerate(xgboost_results, 1):\n",
        "    print(f\"{rank}. {option} (Score: {score:.4f})\")\n",
        "\n",
        "# Calculate Kendall's Tau correlations\n",
        "pagerank_order = [option for option, _ in pagerank_results]\n",
        "trueskill_order = [option for option, _ in trueskill_results]\n",
        "xgboost_order = [option for option, _ in xgboost_results]\n",
        "\n",
        "tau_pr_ts, p_value_pr_ts = kendalltau(pagerank_order, trueskill_order)\n",
        "tau_pr_xgb, p_value_pr_xgb = kendalltau(pagerank_order, xgboost_order)\n",
        "tau_ts_xgb, p_value_ts_xgb = kendalltau(trueskill_order, xgboost_order)\n",
        "\n",
        "print(f\"\\nKendall's Tau correlation between PageRank and TrueSkill rankings: {tau_pr_ts:.4f} (p-value: {p_value_pr_ts:.4f})\")\n",
        "print(f\"Kendall's Tau correlation between PageRank and XGBoost rankings: {tau_pr_xgb:.4f} (p-value: {p_value_pr_xgb:.4f})\")\n",
        "print(f\"Kendall's Tau correlation between TrueSkill and XGBoost rankings: {tau_ts_xgb:.4f} (p-value: {p_value_ts_xgb:.4f})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DT-1_AE_om6o",
        "outputId": "a82dd7dc-431f-43c1-928c-31b4c6b148c8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-8a5b9d8d4642>:54: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X['pop_vulnerability'] = X['population'] * X['social_vulnerability_score']\n",
            "<ipython-input-4-8a5b9d8d4642>:55: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X['action1_vulnerability'] = X['action_1'] * X['social_vulnerability_score']\n",
            "<ipython-input-4-8a5b9d8d4642>:56: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X['action2_vulnerability'] = X['action_2'] * X['social_vulnerability_score']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PageRank Rankings:\n",
            "1. Repair Water School in Community 3 (Score: 0.1180)\n",
            "2. Repair Water Residential in Community 3 (Score: 0.1180)\n",
            "3. Repair Water Residential in Community 2 (Score: 0.1180)\n",
            "4. Repair Power Residential in Community 3 (Score: 0.1180)\n",
            "5. Repair Power Residential in Community 1 (Score: 0.1164)\n",
            "6. Repair Power Residential in Community 2 (Score: 0.1164)\n",
            "7. Repair Water Commercial in Community 2 (Score: 0.1143)\n",
            "8. Repair Water Residential in Community 1 (Score: 0.1033)\n",
            "9. Repair Water School in Community 1 (Score: 0.0778)\n",
            "\n",
            "TrueSkill Rankings:\n",
            "1. Repair Water School in Community 1 (Score: 29.35 ± 0.83)\n",
            "2. Repair Water Residential in Community 2 (Score: 28.99 ± 0.82)\n",
            "3. Repair Water Residential in Community 1 (Score: 28.70 ± 0.82)\n",
            "4. Repair Water School in Community 3 (Score: 28.19 ± 0.81)\n",
            "5. Repair Power Residential in Community 2 (Score: 25.72 ± 0.80)\n",
            "6. Repair Water Residential in Community 3 (Score: 24.29 ± 0.79)\n",
            "7. Repair Power Residential in Community 1 (Score: 22.55 ± 0.81)\n",
            "8. Repair Water Commercial in Community 2 (Score: 21.61 ± 0.83)\n",
            "9. Repair Power Residential in Community 3 (Score: 20.83 ± 0.85)\n",
            "\n",
            "XGBoost Rankings:\n",
            "1. Repair Water Commercial in Community 2 (Score: 1529.9388)\n",
            "2. Repair Water Residential in Community 3 (Score: 1227.3088)\n",
            "3. Repair Power Residential in Community 3 (Score: 988.3205)\n",
            "4. Repair Water Residential in Community 2 (Score: 878.5871)\n",
            "5. Repair Power Residential in Community 2 (Score: 745.5996)\n",
            "6. Repair Power Residential in Community 1 (Score: 668.5908)\n",
            "7. Repair Water Residential in Community 1 (Score: 657.2054)\n",
            "8. Repair Water School in Community 3 (Score: 425.0322)\n",
            "9. Repair Water School in Community 1 (Score: 205.3973)\n",
            "\n",
            "Kendall's Tau correlation between PageRank and TrueSkill rankings: 0.1667 (p-value: 0.6122)\n",
            "Kendall's Tau correlation between PageRank and XGBoost rankings: 0.3333 (p-value: 0.2595)\n",
            "Kendall's Tau correlation between TrueSkill and XGBoost rankings: -0.0556 (p-value: 0.9195)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RankNet and ListNet"
      ],
      "metadata": {
        "id": "OO_fI9XpjoGR"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3I_QpUCjphdi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy.stats import kendalltau\n",
        "\n",
        "feature_names = ['community', 'population', 'social_vulnerability_score', 'access_to_resources',\n",
        "                 'action_1', 'facility_1', 'community_1', 'action_2', 'facility_2', 'community_2']\n",
        "\n",
        "# Prepare data\n",
        "def prepare_data(df):\n",
        "    X = df[feature_names]\n",
        "    y = df['label']\n",
        "    return X.values, y.values\n",
        "\n",
        "X, y = prepare_data(df)\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "X_train_tensor = torch.FloatTensor(X_train_scaled)\n",
        "y_train_tensor = torch.FloatTensor(y_train)\n",
        "X_test_tensor = torch.FloatTensor(X_test_scaled)\n",
        "y_test_tensor = torch.FloatTensor(y_test)\n",
        "\n",
        "# Dataset and DataLoader\n",
        "class PairwiseDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "train_dataset = PairwiseDataset(X_train_tensor, y_train_tensor)\n",
        "test_dataset = PairwiseDataset(X_test_tensor, y_test_tensor)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# RankNet Model\n",
        "class RankNet(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(RankNet, self).__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_size, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "# ListNet Model\n",
        "class ListNet(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(ListNet, self).__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_size, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "# Training function\n",
        "def train_model(model, train_loader, criterion, optimizer, epochs):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        for X, y in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(X).squeeze()\n",
        "            loss = criterion(outputs, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(train_loader):.4f}\")\n",
        "\n",
        "# Evaluation function\n",
        "def evaluate_model(model, test_loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in test_loader:\n",
        "            outputs = model(X).squeeze()\n",
        "            predicted = (outputs > 0.5).float()\n",
        "            total += y.size(0)\n",
        "            correct += (predicted == y).sum().item()\n",
        "    return correct / total\n",
        "\n",
        "# Train and evaluate RankNet\n",
        "ranknet = RankNet(X_train_scaled.shape[1])\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(ranknet.parameters(), lr=0.001)\n",
        "\n",
        "print(\"Training RankNet...\")\n",
        "train_model(ranknet, train_loader, criterion, optimizer, epochs=50)\n",
        "\n",
        "ranknet_accuracy = evaluate_model(ranknet, test_loader)\n",
        "print(f\"RankNet Accuracy: {ranknet_accuracy:.4f}\")\n",
        "\n",
        "# Train and evaluate ListNet\n",
        "listnet = ListNet(X_train_scaled.shape[1])\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(listnet.parameters(), lr=0.001)\n",
        "\n",
        "print(\"\\nTraining ListNet...\")\n",
        "train_model(listnet, train_loader, criterion, optimizer, epochs=50)\n",
        "\n",
        "listnet_accuracy = evaluate_model(listnet, test_loader)\n",
        "print(f\"ListNet Accuracy: {listnet_accuracy:.4f}\")\n",
        "\n",
        "# Function to get ranking for all repair options\n",
        "def get_nn_ranking(model, scaler, df, feature_names):\n",
        "    all_options = set(df['option1'].unique()) | set(df['option2'].unique())\n",
        "    option_scores = {option: 0 for option in all_options}\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        context = row[['community', 'population', 'social_vulnerability_score', 'access_to_resources']].values\n",
        "        for option in all_options:\n",
        "            action, facility, community = encode_repair_option(option)\n",
        "            feature_values = np.concatenate([context, [action, facility, community, 0, 0, 0]])\n",
        "            feature_values_scaled = scaler.transform([feature_values])\n",
        "            feature_values_tensor = torch.FloatTensor(feature_values_scaled)\n",
        "            score = model(feature_values_tensor).item()\n",
        "            option_scores[option] += score\n",
        "\n",
        "    return sorted(option_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# Get and print rankings\n",
        "ranknet_rankings = get_nn_ranking(ranknet, scaler, df, feature_names)\n",
        "listnet_rankings = get_nn_ranking(listnet, scaler, df, feature_names)\n",
        "\n",
        "print(\"\\nRankNet Rankings:\")\n",
        "for rank, (option, score) in enumerate(ranknet_rankings, 1):\n",
        "    print(f\"{rank}. {option} (Score: {score:.4f})\")\n",
        "\n",
        "print(\"\\nListNet Rankings:\")\n",
        "for rank, (option, score) in enumerate(listnet_rankings, 1):\n",
        "    print(f\"{rank}. {option} (Score: {score:.4f})\")\n",
        "\n",
        "# Compare with previous rankings\n",
        "ranknet_order = [option for option, _ in ranknet_rankings]\n",
        "listnet_order = [option for option, _ in listnet_rankings]\n",
        "\n",
        "for name, order in [(\"RankNet\", ranknet_order), (\"ListNet\", listnet_order)]:\n",
        "    tau_pr, p_value_pr = kendalltau(order, pagerank_order)\n",
        "    tau_ts, p_value_ts = kendalltau(order, trueskill_order)\n",
        "    tau_xgb, p_value_xgb = kendalltau(order, xgboost_order)\n",
        "\n",
        "    print(f\"\\n{name} correlations:\")\n",
        "    print(f\"Kendall's Tau correlation with PageRank: {tau_pr:.4f} (p-value: {p_value_pr:.4f})\")\n",
        "    print(f\"Kendall's Tau correlation with TrueSkill: {tau_ts:.4f} (p-value: {p_value_ts:.4f})\")\n",
        "    print(f\"Kendall's Tau correlation with XGBoost: {tau_xgb:.4f} (p-value: {p_value_xgb:.4f})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i26APq4fjzUA",
        "outputId": "e9c5c38a-5580-4168-9bfe-e6e16d96e379"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training RankNet...\n",
            "Epoch 1/50, Loss: 0.6495\n",
            "Epoch 2/50, Loss: 0.5885\n",
            "Epoch 3/50, Loss: 0.5523\n",
            "Epoch 4/50, Loss: 0.5362\n",
            "Epoch 5/50, Loss: 0.5244\n",
            "Epoch 6/50, Loss: 0.5164\n",
            "Epoch 7/50, Loss: 0.5109\n",
            "Epoch 8/50, Loss: 0.5036\n",
            "Epoch 9/50, Loss: 0.4988\n",
            "Epoch 10/50, Loss: 0.4951\n",
            "Epoch 11/50, Loss: 0.4904\n",
            "Epoch 12/50, Loss: 0.4884\n",
            "Epoch 13/50, Loss: 0.4853\n",
            "Epoch 14/50, Loss: 0.4827\n",
            "Epoch 15/50, Loss: 0.4813\n",
            "Epoch 16/50, Loss: 0.4768\n",
            "Epoch 17/50, Loss: 0.4772\n",
            "Epoch 18/50, Loss: 0.4735\n",
            "Epoch 19/50, Loss: 0.4733\n",
            "Epoch 20/50, Loss: 0.4708\n",
            "Epoch 21/50, Loss: 0.4693\n",
            "Epoch 22/50, Loss: 0.4693\n",
            "Epoch 23/50, Loss: 0.4676\n",
            "Epoch 24/50, Loss: 0.4679\n",
            "Epoch 25/50, Loss: 0.4646\n",
            "Epoch 26/50, Loss: 0.4659\n",
            "Epoch 27/50, Loss: 0.4660\n",
            "Epoch 28/50, Loss: 0.4645\n",
            "Epoch 29/50, Loss: 0.4636\n",
            "Epoch 30/50, Loss: 0.4628\n",
            "Epoch 31/50, Loss: 0.4625\n",
            "Epoch 32/50, Loss: 0.4623\n",
            "Epoch 33/50, Loss: 0.4609\n",
            "Epoch 34/50, Loss: 0.4622\n",
            "Epoch 35/50, Loss: 0.4595\n",
            "Epoch 36/50, Loss: 0.4592\n",
            "Epoch 37/50, Loss: 0.4611\n",
            "Epoch 38/50, Loss: 0.4598\n",
            "Epoch 39/50, Loss: 0.4593\n",
            "Epoch 40/50, Loss: 0.4586\n",
            "Epoch 41/50, Loss: 0.4597\n",
            "Epoch 42/50, Loss: 0.4581\n",
            "Epoch 43/50, Loss: 0.4578\n",
            "Epoch 44/50, Loss: 0.4583\n",
            "Epoch 45/50, Loss: 0.4610\n",
            "Epoch 46/50, Loss: 0.4580\n",
            "Epoch 47/50, Loss: 0.4570\n",
            "Epoch 48/50, Loss: 0.4559\n",
            "Epoch 49/50, Loss: 0.4553\n",
            "Epoch 50/50, Loss: 0.4551\n",
            "RankNet Accuracy: 0.7350\n",
            "\n",
            "Training ListNet...\n",
            "Epoch 1/50, Loss: 0.6611\n",
            "Epoch 2/50, Loss: 0.5955\n",
            "Epoch 3/50, Loss: 0.5540\n",
            "Epoch 4/50, Loss: 0.5318\n",
            "Epoch 5/50, Loss: 0.5171\n",
            "Epoch 6/50, Loss: 0.5056\n",
            "Epoch 7/50, Loss: 0.4976\n",
            "Epoch 8/50, Loss: 0.4913\n",
            "Epoch 9/50, Loss: 0.4862\n",
            "Epoch 10/50, Loss: 0.4818\n",
            "Epoch 11/50, Loss: 0.4786\n",
            "Epoch 12/50, Loss: 0.4760\n",
            "Epoch 13/50, Loss: 0.4727\n",
            "Epoch 14/50, Loss: 0.4734\n",
            "Epoch 15/50, Loss: 0.4707\n",
            "Epoch 16/50, Loss: 0.4691\n",
            "Epoch 17/50, Loss: 0.4684\n",
            "Epoch 18/50, Loss: 0.4649\n",
            "Epoch 19/50, Loss: 0.4649\n",
            "Epoch 20/50, Loss: 0.4630\n",
            "Epoch 21/50, Loss: 0.4645\n",
            "Epoch 22/50, Loss: 0.4634\n",
            "Epoch 23/50, Loss: 0.4623\n",
            "Epoch 24/50, Loss: 0.4614\n",
            "Epoch 25/50, Loss: 0.4635\n",
            "Epoch 26/50, Loss: 0.4605\n",
            "Epoch 27/50, Loss: 0.4618\n",
            "Epoch 28/50, Loss: 0.4594\n",
            "Epoch 29/50, Loss: 0.4615\n",
            "Epoch 30/50, Loss: 0.4593\n",
            "Epoch 31/50, Loss: 0.4568\n",
            "Epoch 32/50, Loss: 0.4575\n",
            "Epoch 33/50, Loss: 0.4588\n",
            "Epoch 34/50, Loss: 0.4571\n",
            "Epoch 35/50, Loss: 0.4564\n",
            "Epoch 36/50, Loss: 0.4564\n",
            "Epoch 37/50, Loss: 0.4566\n",
            "Epoch 38/50, Loss: 0.4543\n",
            "Epoch 39/50, Loss: 0.4559\n",
            "Epoch 40/50, Loss: 0.4575\n",
            "Epoch 41/50, Loss: 0.4559\n",
            "Epoch 42/50, Loss: 0.4538\n",
            "Epoch 43/50, Loss: 0.4537\n",
            "Epoch 44/50, Loss: 0.4561\n",
            "Epoch 45/50, Loss: 0.4551\n",
            "Epoch 46/50, Loss: 0.4529\n",
            "Epoch 47/50, Loss: 0.4557\n",
            "Epoch 48/50, Loss: 0.4538\n",
            "Epoch 49/50, Loss: 0.4545\n",
            "Epoch 50/50, Loss: 0.4547\n",
            "ListNet Accuracy: 0.7375\n",
            "\n",
            "RankNet Rankings:\n",
            "1. Repair Water School in Community 1 (Score: 18064.3498)\n",
            "2. Repair Water Residential in Community 1 (Score: 14607.3805)\n",
            "3. Repair Water Residential in Community 2 (Score: 13041.2553)\n",
            "4. Repair Water School in Community 3 (Score: 11661.0453)\n",
            "5. Repair Water Residential in Community 3 (Score: 8907.0860)\n",
            "6. Repair Water Commercial in Community 2 (Score: 8358.6921)\n",
            "7. Repair Power Residential in Community 1 (Score: 7858.6587)\n",
            "8. Repair Power Residential in Community 2 (Score: 6517.4088)\n",
            "9. Repair Power Residential in Community 3 (Score: 2797.6033)\n",
            "\n",
            "ListNet Rankings:\n",
            "1. Repair Water School in Community 1 (Score: 17956.2187)\n",
            "2. Repair Water Residential in Community 1 (Score: 14097.9954)\n",
            "3. Repair Water Residential in Community 2 (Score: 10532.9487)\n",
            "4. Repair Water School in Community 3 (Score: 8187.4174)\n",
            "5. Repair Water Commercial in Community 2 (Score: 5658.0914)\n",
            "6. Repair Power Residential in Community 1 (Score: 4834.0316)\n",
            "7. Repair Power Residential in Community 2 (Score: 4735.3515)\n",
            "8. Repair Water Residential in Community 3 (Score: 4585.5651)\n",
            "9. Repair Power Residential in Community 3 (Score: -419.4711)\n",
            "\n",
            "RankNet correlations:\n",
            "Kendall's Tau correlation with PageRank: 0.0000 (p-value: 1.0000)\n",
            "Kendall's Tau correlation with TrueSkill: 0.5000 (p-value: 0.0752)\n",
            "Kendall's Tau correlation with XGBoost: -0.2222 (p-value: 0.4767)\n",
            "\n",
            "ListNet correlations:\n",
            "Kendall's Tau correlation with PageRank: 0.1667 (p-value: 0.6122)\n",
            "Kendall's Tau correlation with TrueSkill: 0.4444 (p-value: 0.1194)\n",
            "Kendall's Tau correlation with XGBoost: 0.2778 (p-value: 0.3585)\n"
          ]
        }
      ]
    }
  ]
}